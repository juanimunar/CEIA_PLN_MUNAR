{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue5hxxkdAQJg"
   },
   "source": [
    "<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Vectorización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kCED1hh-Ioyf"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PUbfVnzIIoMj"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMOa4JPSCJ29"
   },
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RIO7b8GjAC17"
   },
   "outputs": [],
   "source": [
    "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WqdaTmO8P1r"
   },
   "source": [
    "Documento 1 --> que dia es hoy \\\n",
    "Documento 2 --> martes el dia de hoy es martes \\\n",
    "Documento 3 --> martes muchas gracias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVHxBRNzCMOS"
   },
   "source": [
    "### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n",
    "- Cada documento transformarlo en una lista de términos\n",
    "- Armar un vector de términos no repetidos de todos los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3ZqTOZzDI7uv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['que', 'dia', 'es', 'hoy']),\n",
       "       list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']),\n",
       "       list(['martes', 'muchas', 'gracias'])], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformo cada documento en una lista de términos\n",
    "listas_terminos = np.char.split(corpus)\n",
    "listas_terminos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n",
      "[1 2 1 2 1 2 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Unifico los términos en un solo array\n",
    "array_terminos = np.concatenate([np.array(lista) for lista in listas_terminos])\n",
    "\n",
    "# Obtengo los términos y su conteo\n",
    "terminos, counts = np.unique(array_terminos, return_counts=True)\n",
    "\n",
    "print(terminos)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUhH983FI7It"
   },
   "source": [
    "### 2- OneHot encoding\n",
    "Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino una función para obtener el One Hot Encoding del corpus\n",
    "def OHE(corpus):\n",
    "    \n",
    "    # Obtengo listas de términos y términos que las integran\n",
    "    listas_terminos = np.char.split(corpus)\n",
    "    array_terminos = np.concatenate([np.array(lista) \n",
    "                                     for lista in listas_terminos])\n",
    "    terminos, count = np.unique(array_terminos, return_counts=True)\n",
    "    \n",
    "    # Obtengo la matriz\n",
    "    matriz_OHE = np.array([np.isin(terminos, listas_terminos[i]).astype(int) \n",
    "                           for i in range(listas_terminos.size)])\n",
    "\n",
    "    return matriz_OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['que', 'dia', 'es', 'hoy'])\n",
      " list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'])\n",
      " list(['martes', 'muchas', 'gracias'])]\n",
      "\n",
      "['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejecuto la función para el corpus\n",
    "print(listas_terminos)\n",
    "print()\n",
    "print(terminos)\n",
    "OHE(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIyWGmCpJVQL"
   },
   "source": [
    "### 3- Vectores de frecuencia\n",
    "Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino una función para obtener los vectores de frecuencia\n",
    "def vectores_frecuencia(corpus):\n",
    "    \n",
    "    # Obtengo listas de terminos y terminos que las integran\n",
    "    listas_terminos = np.char.split(corpus)\n",
    "    array_terminos = np.concatenate([np.array(lista) \n",
    "                                     for lista in listas_terminos])\n",
    "    terminos, count = np.unique(array_terminos, return_counts=True)\n",
    "    \n",
    "    # Recorre la lista de palabras y suma en el vector cuando hay coincidencias\n",
    "    lista_vectores = []\n",
    "    for i in range(listas_terminos.size):\n",
    "        vector = np.zeros(len(terminos), dtype=int)\n",
    "        for palabra in listas_terminos[i]:\n",
    "            coincidencias = (terminos == palabra)\n",
    "            vector = vector + coincidencias\n",
    "        lista_vectores.append(vector)\n",
    "    \n",
    "    # Convierto en array\n",
    "    array_vectores = np.array(lista_vectores)\n",
    "\n",
    "    return array_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['que', 'dia', 'es', 'hoy'])\n",
      " list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'])\n",
      " list(['martes', 'muchas', 'gracias'])]\n",
      "\n",
      "['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejecuto la función para el corpus\n",
    "print(listas_terminos)\n",
    "print()\n",
    "print(terminos)\n",
    "vectores_frecuencia(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_Ot8HvWJcBu"
   },
   "source": [
    "### 4- TF-IDF\n",
    "Data una lista de textos, devolver una matriz con la representacion TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino una función para obtener la matriz TF-IDF\n",
    "def TF_IDF(corpus):\n",
    "    \n",
    "    # Obtengo listas de términos y términos que las integran\n",
    "    listas_terminos = np.char.split(corpus)\n",
    "    array_terminos = np.concatenate([np.array(lista) \n",
    "                                     for lista in listas_terminos])\n",
    "    terminos, count = np.unique(array_terminos, return_counts=True)\n",
    "    \n",
    "    # Obtengo el One Hot Encoding\n",
    "    matriz_OHE = np.array([np.isin(terminos, listas_terminos[i]).astype(int) \n",
    "                           for i in range(listas_terminos.size)])\n",
    "    \n",
    "    # Broadcasting\n",
    "    IDF = np.log10(corpus.size / np.sum(matriz_OHE, axis=0))\n",
    "    \n",
    "    # Factor TF\n",
    "    lista_vectores = []\n",
    "    for i in range(listas_terminos.size):\n",
    "        vector = np.zeros(len(terminos), dtype=int)\n",
    "        for palabra in listas_terminos[i]:\n",
    "            coincidencias = (terminos == palabra)\n",
    "            vector = vector + coincidencias\n",
    "        lista_vectores.append(vector)\n",
    "           \n",
    "    # Convierto en array\n",
    "    TF = np.array(lista_vectores)\n",
    "    \n",
    "    # Obtengo la matriz\n",
    "    matriz_TF_IDF = TF * IDF\n",
    "    \n",
    "    return matriz_TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['que', 'dia', 'es', 'hoy'])\n",
      " list(['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'])\n",
      " list(['martes', 'muchas', 'gracias'])]\n",
      "\n",
      "['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n",
      "\n",
      "[[0 1 0 1 0 1 0 0 1]\n",
      " [1 1 1 1 0 1 1 0 0]\n",
      " [0 0 0 0 1 0 1 1 0]]\n",
      "\n",
      "[[0.     0.1761 0.     0.1761 0.     0.1761 0.     0.     0.4771]\n",
      " [0.4771 0.1761 0.4771 0.1761 0.     0.1761 0.3522 0.     0.    ]\n",
      " [0.     0.     0.     0.     0.4771 0.     0.1761 0.4771 0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# Ejecuto la función para el corpus\n",
    "print(listas_terminos)\n",
    "print()\n",
    "print(terminos)\n",
    "print()\n",
    "print(OHE(corpus))\n",
    "print()\n",
    "print(np.round(TF_IDF(corpus),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMcsfndWJjm_"
   },
   "source": [
    "### 5 - Comparación de documentos\n",
    "Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planteo la similitud coseno entre vectores TF-IDF\n",
    "def similitud_documento(corpus, indice):\n",
    "    \n",
    "    # Obtengo listas de términos y términos que las integran\n",
    "    listas_terminos = np.char.split(corpus)\n",
    "    array_terminos = np.concatenate([np.array(lista) \n",
    "                                     for lista in listas_terminos])\n",
    "    terminos, count = np.unique(array_terminos, return_counts=True)\n",
    "    \n",
    "    # Obtengo el One Hot Encoding\n",
    "    matriz_OHE = np.array([np.isin(terminos, listas_terminos[i]).astype(int) \n",
    "                           for i in range(listas_terminos.size)])\n",
    "    \n",
    "    # Broadcasting\n",
    "    IDF = np.log10(corpus.size / np.sum(matriz_OHE, axis=0))\n",
    "    \n",
    "    # Factor TF\n",
    "    lista_vectores = []\n",
    "    for i in range(listas_terminos.size):\n",
    "        vector = np.zeros(len(terminos), dtype=int)\n",
    "        for palabra in listas_terminos[i]:\n",
    "            coincidencias = (terminos == palabra)\n",
    "            vector = vector + coincidencias\n",
    "        lista_vectores.append(vector)\n",
    "           \n",
    "    # Convierto en array\n",
    "    TF = np.array(lista_vectores)\n",
    "    \n",
    "    # Obtengo la matriz\n",
    "    matriz_TF_IDF = TF * IDF\n",
    "    \n",
    "    # Obtengo el vector de producto punto\n",
    "    dot = np.sum(matriz_TF_IDF[indice]* matriz_TF_IDF, axis=1)\n",
    "    \n",
    "    # Norma del vector\n",
    "    norma_vector = np.linalg.norm(matriz_TF_IDF[indice])\n",
    "    \n",
    "    # Vector de normas\n",
    "    norma_matriz = np.linalg.norm(matriz_TF_IDF, axis = 1)\n",
    "    \n",
    "    # Similitud coseno\n",
    "    vector_similitud = dot / (norma_vector * norma_matriz)\n",
    "    \n",
    "    # Ordeno por similitud coseno, el \"-\" ordena de mayor a menor\n",
    "    orden = np.argsort(- vector_similitud)\n",
    "    \n",
    "    # Obtengo los documentos ordenados\n",
    "    corpus_ordenado = corpus[orden]\n",
    "    \n",
    "    return corpus_ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "que dia es hoy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['que dia es hoy', 'martes el dia de hoy es martes',\n",
       "       'martes muchas gracias'], dtype='<U30')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probemos con el primer documento, se ordena de mayor a menor\n",
    "print(corpus[0])\n",
    "similitud_documento(corpus, 0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5fRYTpympAwJSVbric6dW",
   "collapsed_sections": [],
   "name": "1a - word2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
